{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Product Demand - Analysis & Models\n",
    "**Data Source:** [Kaggle](https://www.kaggle.com/felixzhao/productdemandforecasting)\n",
    "\n",
    "**Data Description from Kaggle:** *The dataset contains historical product demand for a manufacturing company with footprints globally. The company provides thousands of products within dozens of product categories. There are four central warehouses to ship products within the region it is responsible for. Since the products are manufactured in different locations all over the world, it normally takes more than one month to ship products via ocean to different central warehouses. If forecasts for each product in different central with reasonable accuracy for the monthly demand for month after next can be achieved, it would be beneficial to the company in multiple ways.*\n",
    "\n",
    "**Objective:** *Is it possible to make forecasts for thousands of products (some of them are highly variable in terms of monthly demand) for the the month after next?* <br/>\n",
    "The latest data month is Jan 2017, thus forecast is for Mar 2017 (onwards). <br/>\n",
    "\n",
    "RMSE is used as performance metric in this forecast.\n",
    "\n",
    "**Assumptions:** <br/>\n",
    "A1/ Date refers to shipping date, not order date. Otherwise, forecast cannot be done. Shipping date indicates the time when products need to be avaiable at these warehouse. <br/>\n",
    "A2/ Order demand refers to the order quantity by customers (actual demands), not the order quantity that can be fulfilled by warehouses. <br/>\n",
    "Other assumptions will be made throughout the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import attrgetter\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from prophet import Prophet\n",
    "\n",
    "# For auto ARIMA functionality\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'item_id', 'date', 'quantity', 'cost (CLP)', 'delivery_date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"data_purchases_2.csv\")\n",
    "data.dtypes\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ All columns are formatted as characters and need to be reformatted: <br/> \n",
    "-**Date** to datetime. <br/>\n",
    "-**Order_Demand** to numeric. Order_Demand values include negative numbers that are formated as \"(number)\". These values need to be reformatted as \"-number\" before being converted to numeric.\n",
    "\n",
    "2/ Warehouse and category information do not contribute to forecasting and will be removed. <br/>\n",
    "- **Warehouse:** As per my understanding from data description, the four central warehouses serve demands for the same region. Therefore, the forecast will be performed for total demands in the region, without consideration of warehouse information. Product quantity per warehouse will be calculated based on other information like warehouse capacity and transportation cost, which is not in the scope of this demand forecasting. <br/>\n",
    "- **Product_Category:** There is no other information to understand about product characteristics in each category. Meanwhile, the number of products per category is high, which makes visualization on data patterns of products per category impossible. Thus, it is difficult to understand products' data patterns in accordance with category number. Category column does not well explain demands in this dataset, and thus can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'date', 'quantity', 'delivery_date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Format Date to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "\n",
    "# Drop warehouse and category columns\n",
    "data = data.drop(columns=['id'])\n",
    "data = data.drop(columns=['cost (CLP)'])\n",
    "\n",
    "# Sort data by period\n",
    "data = data.sort_values('date').reset_index().drop('index',axis=1)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types\n",
      "item_id                   int64\n",
      "date             datetime64[ns]\n",
      "quantity                  int64\n",
      "delivery_date            object\n",
      "dtype: object\n",
      "\t\n",
      "   item_id       date  quantity delivery_date\n",
      "0     1810 2020-01-13         3     1/25/2020\n",
      "1     1804 2020-01-13         2     1/25/2020\n",
      "2     1856 2020-01-13         8     1/24/2020\n",
      "3     1803 2020-01-13         5     1/28/2020\n",
      "4     1815 2020-01-13         2     1/23/2020\n",
      "\t\n",
      "Data Dimension (8517, 4)\n",
      "\t\n",
      "The number of products is 81\n",
      "Period range is from 2020-01-13 00:00:00 to 2024-03-04 00:00:00\n",
      "Order Qty is from 1 to 151\n",
      "\t\n",
      "Number of missing values by column [0, 0, 0, 0]\n",
      "All missing values are in Date column.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Types\")\n",
    "print(data.dtypes)\n",
    "print(\"\\t\")\n",
    "\n",
    "print(data.head())\n",
    "print(\"\\t\")\n",
    "\n",
    "print(\"Data Dimension\",data.shape)\n",
    "print(\"\\t\")\n",
    "\n",
    "print(\"The number of products is\",len(data['item_id'].value_counts().index))\n",
    "print(\"Period range is from\",data['date'].min(),\"to\", data['date'].max())\n",
    "print(\"Order Qty is from\",data['quantity'].min(),\"to\", data['quantity'].max())\n",
    "print(\"\\t\")\n",
    "\n",
    "print('Number of missing values by column',[sum(data[i].isnull()) for i in data.columns])\n",
    "print('All missing values are in Date column.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregate data by month\n",
    "Forecasting is performed at monthly horizons, thus the dataset should first be aggregated by month. Date is extracted with Month & Year only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>Period</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1803</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1814</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1815</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1856</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1810</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id   Period  quantity\n",
       "0     1803  2020-01         5\n",
       "1     1814  2020-01        16\n",
       "2     1815  2020-01        17\n",
       "3     1856  2020-01         8\n",
       "4     1810  2020-01         5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'] = data['date'].dt.to_period('M')\n",
    "data = data.rename(columns = {\"date\": 'Period'})\n",
    "data = data.groupby(['item_id','Period'])['quantity'].sum().reset_index().sort_values('Period'\n",
    "            ).reset_index().drop('index',axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if periods in dataset is continuous\n",
    "# Create a duration with continuous periods\n",
    "full_period = pd.date_range('2020-01-01','2023-12-31', freq='MS').to_period('M')\n",
    "full_period = set(full_period)\n",
    "data_period = set(data['Period'])\n",
    "full_period.difference(data_period)\n",
    "# The missing periods are 5 months in 2011, including Feb, Mar, Apr, Jul, and Aug.\n",
    "# There are various possible reasons for the missing periods: No demands are in these months, warehouses to be\n",
    "# closed in these months for some reason, missing data in these periods, etc.\n",
    "# To ensure that the training data will not be misleading, all data before Sep 2011 will be removed.\n",
    "#data = data.loc[data['Period'] > '2011-08']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check to see which products are eligible for forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some analysis is done to see if any products should be excluded from the forecasting. <br/>\n",
    "Several criteria are as below: <br/>\n",
    "**1/** All data in Jan, 2017 should be removed; otherwise, model interpretation will be misled. <br/>\n",
    "Reason: The latest date in this dataset is 2017/01/09 while forecasting is for monthly horizon. <br/>\n",
    "**2/** Products that have no order quantities in 2016 will be removed. <br/>\n",
    "Reason: It is highly likely that the products have been stopped already and will have no future demand. The duration of 1 year helps cover the cases of seasonal products.  <br/>\n",
    "**3/** Products with demand history less than 24 months will be removed. <br/>\n",
    "Reason: A minimum of 2 years' data is required to forecast trends and seasonality using statistical forecasting methods. Also, in cases when history is too short (6 months for example), the products are likely to be new products and forecasting methods for new products are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criteria 1: Remove data in Jan, 2017\n",
    "# data = data.loc[data['Period']<'2017-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criteria 2: Remove stopped products\n",
    "# latest_datamonth = data.groupby('Product_Code')['Period'].max().reset_index()\n",
    "# latest_datamonth = latest_datamonth.loc[latest_datamonth['Period'] > '2015-12']\n",
    "# data = data.loc[data['Product_Code'].isin(latest_datamonth['Product_Code'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criteria 3: Remove new products\n",
    "# duration_data = data.groupby('Product_Code').agg({'Period': ['min', 'max']}).reset_index()\n",
    "# duration_data['Duration'] = (duration_data[('Period', 'max')] - duration_data[('Period', 'min')]\n",
    "#                             ).apply(attrgetter('n')) + 1\n",
    "# duration_data = duration_data.loc[duration_data['Duration'] > 24 ]\n",
    "# data = data.loc[data['Product_Code'].isin(duration_data['Product_Code'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct time series in a columnar format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\56979\\AppData\\Local\\Temp\\ipykernel_25356\\2208093037.py:1: FutureWarning: The provided callable <function sum at 0x000001F8FF8334C0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  data = pd.pivot_table(data, values = 'quantity', index = 'Period', columns = 'item_id',aggfunc=np.sum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1785</th>\n",
       "      <th>1786</th>\n",
       "      <th>1787</th>\n",
       "      <th>1788</th>\n",
       "      <th>1789</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>1792</th>\n",
       "      <th>1793</th>\n",
       "      <th>1794</th>\n",
       "      <th>...</th>\n",
       "      <th>1856</th>\n",
       "      <th>1857</th>\n",
       "      <th>1858</th>\n",
       "      <th>1859</th>\n",
       "      <th>1860</th>\n",
       "      <th>1861</th>\n",
       "      <th>1863</th>\n",
       "      <th>1866</th>\n",
       "      <th>1867</th>\n",
       "      <th>1869</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02</th>\n",
       "      <td>37.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03</th>\n",
       "      <td>109.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04</th>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05</th>\n",
       "      <td>66.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1785  1786  1787  1788   1789   1790  1791  1792  1793  1794  ...  \\\n",
       "Period                                                                  ...   \n",
       "2020-01    0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2020-02   37.0  50.0  12.0  14.0   20.0   40.0  17.0  25.0  37.0  20.0  ...   \n",
       "2020-03  109.0  64.0  27.0  67.0  108.0  162.0  30.0  56.0  47.0  55.0  ...   \n",
       "2020-04   54.0  52.0  13.0  70.0   38.0  101.0  28.0  31.0  42.0  40.0  ...   \n",
       "2020-05   66.0  55.0  21.0  85.0   85.0  117.0  23.0  38.0  41.0  50.0  ...   \n",
       "\n",
       "         1856  1857  1858  1859  1860  1861  1863  1866  1867  1869  \n",
       "Period                                                               \n",
       "2020-01   8.0   0.0   8.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2020-02  14.0   0.0   2.0   8.0   0.0   0.0   0.0   6.0   0.0   0.0  \n",
       "2020-03   9.0   0.0   0.0   0.0   8.0   3.0   9.0   2.0   6.0   6.0  \n",
       "2020-04  13.0   0.0   0.0   0.0  19.0  23.0  17.0   2.0  25.0  11.0  \n",
       "2020-05   5.0  17.0   2.0   0.0  25.0  21.0  15.0   2.0  28.0  15.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.pivot_table(data, values = 'quantity', index = 'Period', columns = 'item_id',aggfunc=np.sum\n",
    "                     ).reset_index().rename_axis(\"\", axis=\"columns\")\n",
    "\n",
    "#Fill in missing values with 0. Months with missing values are implied to have zero demands.\n",
    "data = data.fillna(0)\n",
    "data = data.set_index('Period')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # The dataset includes data for 2061 products, which takes Python too long to return model results.\n",
    "# # Thus, I sampled only several products with different patterns for demonstration purpose\n",
    "# data = data[['Product_0002','Product_0138','Product_0597','Product_0875','Product_2066',\n",
    "#                'Product_2091','Product_2127','Product_2165']]\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try with models\n",
    "Forecasting methods: Each product will be tested with different models to find out the models which suit with products' data patterns the most. Performance will be compared using RMSE. After the best model is picked, product forecast will be created by the model trained on the most recent data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       item_id   Period  quantity\n",
      "0        1803  2020-01         5\n",
      "1        1814  2020-01        16\n",
      "2        1815  2020-01        17\n",
      "3        1856  2020-01         8\n",
      "4        1810  2020-01         5\n",
      "...       ...      ...       ...\n",
      "3505     1829  2024-03        13\n",
      "3506     1840  2024-03         4\n",
      "3507     1856  2024-03         2\n",
      "3508     1869  2024-03        13\n",
      "3509     1833  2024-03         2\n",
      "\n",
      "[3510 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "# function to split train and test set\n",
    "# history length of a product starts from the month of first order, not all products have the same history length\n",
    "# the function is to split train-test based on product's history length instead of dataset length\n",
    "def train_test(data):\n",
    "    myList = data.tolist()\n",
    "    i = myList.index(next(filter(lambda x: x!=0, myList)))\n",
    "    data = data.iloc[i:,]\n",
    "    train = data[:int(0.7*(len(data)))]\n",
    "    test = data[int(0.7*len(data)):]\n",
    "    return train, test, data\n",
    "\n",
    "# create data for forecasting\n",
    "start = data.index.tolist()[-1] + 3\n",
    "fcastperiods = 12  # forecast periods is subject to change by forecast users\n",
    "full_period = [start + x for x in range(0,fcastperiods)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sqrt\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "\n",
    "def arimafcast(data, fcastperiods=12):\n",
    "    warnings.filterwarnings(\"ignore\")  # Suppress warnings\n",
    "    Arima = ['Arima']\n",
    "    ArimaFcastPerf = pd.DataFrame({'Models': Arima})\n",
    "    \n",
    "    full_period = pd.date_range(start=data.index.max() + pd.DateOffset(months=1), \n",
    "                                periods=fcastperiods, freq='M')\n",
    "    ArimaData = pd.DataFrame({'Period': full_period, 'Model': 'Arima'})\n",
    "    \n",
    "    def find_order(series):\n",
    "        # Simple function to determine order based on ADF test\n",
    "        d = adfuller(series)[1] > 0.05  # If p-value > 0.05, d=1, else d=0\n",
    "        return (1, int(d), 1)  # Simple (1,d,1) model\n",
    "    \n",
    "    for i in data.columns:\n",
    "        try:\n",
    "            train, test, full = train_test(data[i])\n",
    "            \n",
    "            # Test model\n",
    "            order = find_order(train)\n",
    "            model_pred = ARIMA(train, order=order)\n",
    "            results_pred = model_pred.fit()\n",
    "            pred = results_pred.forecast(steps=len(test))\n",
    "            ArimaFcastPerf[i] = sqrt(mean_squared_error(test, pred))\n",
    "            \n",
    "            # Forecast model\n",
    "            order = find_order(full)\n",
    "            model_fc = ARIMA(full, order=order)\n",
    "            results_fc = model_fc.fit()\n",
    "            forecast = results_fc.forecast(steps=fcastperiods)\n",
    "            ArimaData[i] = np.round(forecast)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing column {i}: {str(e)}\")\n",
    "            ArimaFcastPerf[i] = np.nan\n",
    "            ArimaData[i] = np.nan\n",
    "            \n",
    "    return ArimaFcastPerf, ArimaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "# build function to run model for all columns\n",
    "SArima = ['SArima']\n",
    "SArimaFcastPerf = pd.DataFrame({'Models': SArima})\n",
    "SArimaData = pd.DataFrame({'Period': full_period, 'Model': 'SArima'})\n",
    "\n",
    "def sarimafcast(data):\n",
    "    for i in data.columns:\n",
    "        try:\n",
    "            train, test, full = train_test(data[i])\n",
    "            \n",
    "            # Test model\n",
    "            model_pred = auto_arima(train, start_p=0, start_q=0, max_p=3, max_q=3,\n",
    "                                  m=12, trace=True, \n",
    "                                  error_action='ignore', suppress_warnings=True)\n",
    "            model_pred.fit(train)\n",
    "            pred = np.round(model_pred.predict(n_periods=len(test)))\n",
    "            SArimaFcastPerf[i] = sqrt(mean_squared_error(test,pred))\n",
    "            \n",
    "            # Forecast model\n",
    "            model_fc = auto_arima(full, start_p=0, start_q=0, max_p=3, max_q=3,\n",
    "                                  m=12, trace=True, \n",
    "                                  error_action='ignore', suppress_warnings=True)\n",
    "            model_fc.fit(full)\n",
    "            forecast = np.round(model_fc.predict(n_periods=fcastperiods+2))\n",
    "            SArimaData[i] = forecast[-fcastperiods:]\n",
    "        except:\n",
    "            SArimaFcastPerf[i] = np.nan\n",
    "            SArimaData[i] = np.nan\n",
    "    return SArimaFcastPerf, SArimaData\n",
    "sarimafcast(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# build function to run model for all columns\n",
    "SES = ['SES']\n",
    "SESFcastPerf = pd.DataFrame({'Models': SES})\n",
    "SESData = pd.DataFrame({'Period': full_period, 'Model': 'SES'})\n",
    "\n",
    "def sesfcast(data):\n",
    "    for i in data.columns:\n",
    "        try:\n",
    "            train, test, full = train_test(data[i])\n",
    "                \n",
    "            # Test model\n",
    "            model_pred = SimpleExpSmoothing(train).fit()\n",
    "            pred = np.round(model_pred.forecast(len(test)))\n",
    "            SESFcastPerf[i] = sqrt(mean_squared_error(test,pred))\n",
    "                \n",
    "            # Forecast model\n",
    "            model_fc = SimpleExpSmoothing(full).fit()\n",
    "            forecast = np.round(model_fc.forecast(fcastperiods+2))\n",
    "            SESData[i] = forecast.tolist()[-fcastperiods:]            \n",
    "        except:\n",
    "            SESFcastPerf[i] = np.nan\n",
    "            SESData[i] = np.nan\n",
    "    return SESFcastPerf, SESData\n",
    "sesfcast(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Double Exponential Smoothing\n",
    "Note: Double & Triple Exponential Smoothing only apply to positive data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# build function to run model for all columns\n",
    "DES = ['DES']\n",
    "DESFcastPerf = pd.DataFrame({'Models': DES})\n",
    "DESData = pd.DataFrame({'Period': full_period, 'Model': 'DES'})\n",
    "\n",
    "def desfcast(data):\n",
    "    for i in data.columns:\n",
    "        try:\n",
    "            train, test, full = train_test(data[i])\n",
    "            if (train.min() != 0) and (test.min() !=0):\n",
    "                # Test model\n",
    "                model_pred = Holt(train,damped=True).fit()\n",
    "                pred = np.round(model_pred.forecast(len(test)))\n",
    "                DESFcastPerf[i] = sqrt(mean_squared_error(test,pred))\n",
    "                    \n",
    "                # Forecast model\n",
    "                model_fc = Holt(full,damped=True).fit()\n",
    "                forecast = np.round(model_fc.forecast(fcastperiods+2))\n",
    "                DESData[i] = forecast.tolist()[-fcastperiods:]\n",
    "            else:\n",
    "                DESFcastPerf[i] = np.nan\n",
    "                DESData[i] = np.nan  \n",
    "        except:\n",
    "            DESFcastPerf[i] = np.nan\n",
    "            DESData[i] = np.nan\n",
    "    return DESFcastPerf, DESData\n",
    "desfcast(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Triple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# build function to run model for all columns\n",
    "TES = ['TES']\n",
    "TESFcastPerf = pd.DataFrame({'Models': TES})\n",
    "TESData = pd.DataFrame({'Period': full_period, 'Model': 'TES'})\n",
    "\n",
    "def tesfcast(data):\n",
    "    for i in data.columns:\n",
    "        try:\n",
    "            train, test, full = train_test(data[i])\n",
    "            if (train.min() != 0) and (test.min() != 0):\n",
    "                # Test model                \n",
    "                model_pred = ExponentialSmoothing(train, seasonal_periods=12, \n",
    "                                                 trend='add', seasonal='mul', damped=True\n",
    "                                                ).fit(optimized=True,use_boxcox=True)\n",
    "                pred = np.round(model_pred.forecast(len(test)))\n",
    "                TESFcastPerf[i] = sqrt(mean_squared_error(test,pred))\n",
    "                    \n",
    "                # Forecast model\n",
    "                model_fc = ExponentialSmoothing(full, seasonal_periods=12, \n",
    "                                                 trend='add', seasonal='mul', damped=True\n",
    "                                                ).fit(optimized=True,use_boxcox=True)\n",
    "                forecast = np.round(model_fc.forecast(fcastperiods+2))                \n",
    "                TESData[i] = forecast.tolist()[-fcastperiods:]\n",
    "            else:\n",
    "                TESFcastPerf[i] = np.nan\n",
    "                TESData[i] = np.nan       \n",
    "        except:\n",
    "            TESFcastPerf[i] = np.nan\n",
    "            TESData[i] = np.nan   \n",
    "    return TESFcastPerf, TESData\n",
    "tesfcast(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# build function to run model for all columns\n",
    "Prophetf = ['Prophet']\n",
    "ProphetfFcastPerf = pd.DataFrame({'Models': Prophetf})\n",
    "ProphetfData = pd.DataFrame({'Period': full_period, 'Model': 'Prophet'})\n",
    "    \n",
    "def prophetfForecast(data): \n",
    "    for i in data.columns:\n",
    "        try:\n",
    "            myList = data[i].tolist()\n",
    "            j = myList.index(next(filter(lambda x: x!=0, myList)))\n",
    "            temp = data.iloc[j:,]        \n",
    "            temp['ds']=temp.index.astype('datetime64[ns]')\n",
    "            temp = temp.reset_index(drop=True)\n",
    "            temp = temp.rename(columns = {i:'y'})\n",
    "            temp = temp.loc[:,['ds','y']]\n",
    "                \n",
    "            train = temp[:int(2/3*(len(temp)))]\n",
    "            test = temp[int(2/3*len(temp)):]\n",
    "               \n",
    "            # Test model\n",
    "            model_pred = Prophet()\n",
    "            model_pred.fit(train)\n",
    "            pred = model_pred.predict(test)\n",
    "            ProphetfFcastPerf[i] = sqrt(mean_squared_error(test['y'].values,pred['yhat'].values))\n",
    "                \n",
    "            # Forecast model\n",
    "            model_fc = Prophet()\n",
    "            model_fc.fit(temp)\n",
    "                        \n",
    "            fc_ds = ProphetfData.copy().set_index('Period')\n",
    "            fc_ds['ds']=fc_ds.index.astype('datetime64[ns]')\n",
    "            fc_ds = fc_ds.reset_index(drop=True).drop('Model',axis=1)\n",
    "                \n",
    "            forecast = model_fc.predict(fc_ds)\n",
    "            ProphetfData[i] = np.round(forecast['yhat'].values)\n",
    "        except:\n",
    "            ProphetfFcastPerf[i] = np.nan\n",
    "            ProphetfData[i] = np.nan\n",
    "    return ProphetfFcastPerf, ProphetfData    \n",
    "prophetfForecast(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare and select the best model for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_0002</th>\n",
       "      <th>Product_0138</th>\n",
       "      <th>Product_0597</th>\n",
       "      <th>Product_0875</th>\n",
       "      <th>Product_2066</th>\n",
       "      <th>Product_2091</th>\n",
       "      <th>Product_2127</th>\n",
       "      <th>Product_2165</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arima</th>\n",
       "      <td>118217.407066</td>\n",
       "      <td>1920.982657</td>\n",
       "      <td>4.339739</td>\n",
       "      <td>408.088226</td>\n",
       "      <td>239.215384</td>\n",
       "      <td>102.328280</td>\n",
       "      <td>165.067495</td>\n",
       "      <td>83.539779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SArima</th>\n",
       "      <td>274631.574246</td>\n",
       "      <td>1920.982657</td>\n",
       "      <td>4.339739</td>\n",
       "      <td>559.418493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.328280</td>\n",
       "      <td>165.067495</td>\n",
       "      <td>83.539779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SES</th>\n",
       "      <td>158304.234195</td>\n",
       "      <td>2229.192785</td>\n",
       "      <td>2.886751</td>\n",
       "      <td>544.968806</td>\n",
       "      <td>231.796737</td>\n",
       "      <td>102.033554</td>\n",
       "      <td>165.067495</td>\n",
       "      <td>83.539779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DES</th>\n",
       "      <td>158599.354591</td>\n",
       "      <td>1536.538454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TES</th>\n",
       "      <td>192662.202227</td>\n",
       "      <td>1306.719376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prophet</th>\n",
       "      <td>319742.296789</td>\n",
       "      <td>4842.383948</td>\n",
       "      <td>5.466904</td>\n",
       "      <td>960.321731</td>\n",
       "      <td>212.299737</td>\n",
       "      <td>206.114540</td>\n",
       "      <td>471.901199</td>\n",
       "      <td>151.607379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Product_0002  Product_0138  Product_0597  Product_0875  \\\n",
       "Models                                                             \n",
       "Arima    118217.407066   1920.982657      4.339739    408.088226   \n",
       "SArima   274631.574246   1920.982657      4.339739    559.418493   \n",
       "SES      158304.234195   2229.192785      2.886751    544.968806   \n",
       "DES      158599.354591   1536.538454           NaN           NaN   \n",
       "TES      192662.202227   1306.719376           NaN           NaN   \n",
       "Prophet  319742.296789   4842.383948      5.466904    960.321731   \n",
       "\n",
       "         Product_2066  Product_2091  Product_2127  Product_2165  \n",
       "Models                                                           \n",
       "Arima      239.215384    102.328280    165.067495     83.539779  \n",
       "SArima            NaN    102.328280    165.067495     83.539779  \n",
       "SES        231.796737    102.033554    165.067495     83.539779  \n",
       "DES               NaN           NaN           NaN           NaN  \n",
       "TES               NaN           NaN           NaN           NaN  \n",
       "Prophet    212.299737    206.114540    471.901199    151.607379  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine all performance tables\n",
    "FcastPerf = pd.concat([ArimaFcastPerf,SArimaFcastPerf,SESFcastPerf,DESFcastPerf,TESFcastPerf,ProphetfFcastPerf]\n",
    "                     ).set_index('Models')\n",
    "FcastPerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_0002</th>\n",
       "      <th>Product_0138</th>\n",
       "      <th>Product_0597</th>\n",
       "      <th>Product_0875</th>\n",
       "      <th>Product_2066</th>\n",
       "      <th>Product_2091</th>\n",
       "      <th>Product_2127</th>\n",
       "      <th>Product_2165</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arima</td>\n",
       "      <td>TES</td>\n",
       "      <td>SES</td>\n",
       "      <td>Arima</td>\n",
       "      <td>Prophet</td>\n",
       "      <td>SES</td>\n",
       "      <td>Arima</td>\n",
       "      <td>Arima</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product_0002 Product_0138 Product_0597 Product_0875 Product_2066  \\\n",
       "0        Arima          TES          SES        Arima      Prophet   \n",
       "\n",
       "  Product_2091 Product_2127 Product_2165  \n",
       "0          SES        Arima        Arima  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find best model for each product\n",
    "Model = pd.DataFrame()\n",
    "\n",
    "for i in FcastPerf.columns:\n",
    "    # Find the one with lowest RMSE. Choose the first one in case of more than 1 min values.\n",
    "    Model[i] = list([FcastPerf.loc[FcastPerf[i] == FcastPerf[i].min()].index[0]])\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arima': ['Product_0002', 'Product_0875', 'Product_2127', 'Product_2165'],\n",
       " 'SArima': [],\n",
       " 'SES': ['Product_0597', 'Product_2091'],\n",
       " 'DES': [],\n",
       " 'TES': ['Product_0138'],\n",
       " 'Prophet': ['Product_2066']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter list of products per model\n",
    "model_dict = {}\n",
    "model_list = ['Arima', 'SArima', 'SES', 'DES', 'TES', 'Prophet']\n",
    "for i in model_list:\n",
    "    model_dict[i] = []\n",
    "\n",
    "for i in Model.columns:\n",
    "    for j in model_list:\n",
    "        if any(Model[i] == j):\n",
    "            model_dict[j].append(i)\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract forecast from equivalent models to the final forecast dataframe\n",
    "AllForecast = pd.concat([ArimaData, SArimaData, SESData, DESData, TESData, ProphetfData])\n",
    "FinalForecast = pd.DataFrame({'Period': full_period})\n",
    "\n",
    "for i in model_list:\n",
    "    for j in model_dict[i]:\n",
    "        FinalForecast[j] = AllForecast.loc[AllForecast['Model'] == i][j]\n",
    "FinalForecast = FinalForecast.set_index('Period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntkcu\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Combine historical and forecast data. Insert Data_Type column for filter purpose and move it to front.\n",
    "HistoricalData = data[sorted(data)]\n",
    "FinalForecast = FinalForecast[sorted(FinalForecast)]\n",
    "FinalData = pd.concat([HistoricalData,FinalForecast])\n",
    "    \n",
    "FinalData['Data Type'] = np.nan\n",
    "FinalData['Data Type'].iloc[:-fcastperiods] = 'Historical Data'\n",
    "FinalData['Data Type'].iloc[-fcastperiods:] = 'Forecast'\n",
    "co_list = FinalData.columns.tolist() \n",
    "co_list.insert(0, co_list.pop(co_list.index('Data Type'))) \n",
    "FinalData = FinalData.reindex(columns= co_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Product_0002</th>\n",
       "      <th>Product_0138</th>\n",
       "      <th>Product_0597</th>\n",
       "      <th>Product_0875</th>\n",
       "      <th>Product_2066</th>\n",
       "      <th>Product_2091</th>\n",
       "      <th>Product_2127</th>\n",
       "      <th>Product_2165</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-09</th>\n",
       "      <td>Historical Data</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10</th>\n",
       "      <td>Historical Data</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11</th>\n",
       "      <td>Historical Data</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12</th>\n",
       "      <td>Historical Data</td>\n",
       "      <td>221000.0</td>\n",
       "      <td>5812.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01</th>\n",
       "      <td>Historical Data</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10</th>\n",
       "      <td>Forecast</td>\n",
       "      <td>131138.0</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11</th>\n",
       "      <td>Forecast</td>\n",
       "      <td>131138.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12</th>\n",
       "      <td>Forecast</td>\n",
       "      <td>131138.0</td>\n",
       "      <td>3541.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01</th>\n",
       "      <td>Forecast</td>\n",
       "      <td>131138.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02</th>\n",
       "      <td>Forecast</td>\n",
       "      <td>131138.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Data Type  Product_0002  Product_0138  Product_0597  \\\n",
       "Period                                                               \n",
       "2011-09  Historical Data           0.0           0.0           0.0   \n",
       "2011-10  Historical Data           0.0           0.0           0.0   \n",
       "2011-11  Historical Data           0.0        2040.0           0.0   \n",
       "2011-12  Historical Data      221000.0        5812.0           0.0   \n",
       "2012-01  Historical Data       65000.0        1590.0           0.0   \n",
       "...                  ...           ...           ...           ...   \n",
       "2017-10         Forecast      131138.0        3939.0           2.0   \n",
       "2017-11         Forecast      131138.0        2116.0           2.0   \n",
       "2017-12         Forecast      131138.0        3541.0           2.0   \n",
       "2018-01         Forecast      131138.0        1467.0           2.0   \n",
       "2018-02         Forecast      131138.0        2178.0           2.0   \n",
       "\n",
       "         Product_0875  Product_2066  Product_2091  Product_2127  Product_2165  \n",
       "Period                                                                         \n",
       "2011-09        5450.0           0.0           0.0           0.0           0.0  \n",
       "2011-10           0.0           0.0           0.0           0.0           0.0  \n",
       "2011-11           0.0           0.0           0.0           0.0           0.0  \n",
       "2011-12           0.0           0.0           0.0           0.0         107.0  \n",
       "2012-01           0.0           0.0           0.0           0.0         115.0  \n",
       "...               ...           ...           ...           ...           ...  \n",
       "2017-10         261.0          90.0          98.0         132.0          91.0  \n",
       "2017-11         261.0         214.0          98.0         132.0          91.0  \n",
       "2017-12         261.0         110.0          98.0         132.0          91.0  \n",
       "2018-01         261.0         228.0          98.0         132.0          91.0  \n",
       "2018-02         261.0         227.0          98.0         132.0          92.0  \n",
       "\n",
       "[76 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save final data\n",
    "#FinalData.to_csv(\"FinalData.csv\")\n",
    "FinalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each product column in the final data   \n",
    "for i in FinalData.columns[1:]:\n",
    "    ax = FinalData[i].iloc[:-fcastperiods].plot(figsize=(15, 5), color ='green')\n",
    "    FinalData[i].iloc[-fcastperiods:].plot(ax=ax, color ='red')\n",
    "    fig = ax.get_figure()\n",
    "    plt.show(block=False)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations of this forecast:** <br/>\n",
    "1/ *Limited number of models:* It seems that data patterns of the products at this company vary alot. The models built could not capture all data patterns and return meaningful forecasts. <br/>\n",
    "2/ *No external factors explained:* The forecast is based on historical data only and doesnt incorporate any external information like economic conditions, product price policy changes, future promotions, etc. <br/>\n",
    "3/ *No consideration of returns impact:* Order returns can make negative impact on future demand. For example, customers may leave, which leads to a drop in future demand. However, there is not information to make any assumptions about this impact in this forecasting. <br/>\n",
    "4/ *Omitted missing values:* It's impossible to measure the impact of removing missing values in this dataset. <br/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
